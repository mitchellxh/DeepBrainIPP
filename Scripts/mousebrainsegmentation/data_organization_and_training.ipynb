{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps:\n",
    "\n",
    "1. MRIs with different resolution obtained from different instrument or imaging parameters needs to be resampled to\n",
    "    an unform voxel spacing\n",
    "2. The apply Data augmentation to increase variability and number of training sample\n",
    "3. Make sure all volumes have same dimension\n",
    "4. Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: MRIs with different resolutions obtained from different instruments or imaging parameters need to be resampled to an unform voxel spacing\n",
    "\n",
    "#### Change the value of following parameters: \n",
    "\n",
    "volume_path=\"Input path wehere your training dataset is stored\"\n",
    "\n",
    "out_path=\"Output path wehere you want to store resampled volumes\"\n",
    "\n",
    "new_spacing = Resolution that you choose to resample all MRIs if you have various resolution\n",
    "\n",
    "size=Input volume dimension that you choose to train your model. Make sure your available gpu memory support it and it encompasess all MRIs. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "from medpy.io import load,save\n",
    "import os, shutil, glob\n",
    "    \n",
    "def resample_volume(volume_path,ismask, new_spacing,size ,out_path,basename):\n",
    "    if ismask==1:\n",
    "        interpolator = sitk.sitkNearestNeighbor\n",
    "    else:\n",
    "        interpolator = sitk.sitkBSpline\n",
    "  \n",
    "    volume = sitk.ReadImage(volume_path) # read and cast to float32\n",
    "    original_spacing = volume.GetSpacing()\n",
    "    original_size = volume.GetSize()\n",
    "    original_direction=volume.GetDirection()\n",
    "    original_origin=volume.GetOrigin()\n",
    "    offset_origin=np.subtract(new_spacing, original_spacing)/2\n",
    "    \n",
    "    \n",
    "    new_size = [int(round(osz*ospc/nspc)) for osz,ospc,nspc in zip(original_size, original_spacing, new_spacing)]\n",
    "    #print(new_size)\n",
    "    resampled_img=sitk.Resample(volume, new_size, sitk.Transform(), interpolator,\n",
    "                         original_origin+offset_origin, new_spacing, original_direction, 0,\n",
    "                         volume.GetPixelID())\n",
    "    if(os.path.exists(out_path+\"res.nii.gz\")):\n",
    "        os.remove(out_path+\"res.nii.gz\")\n",
    "    sitk.WriteImage(resampled_img,out_path+\"res.nii.gz\")\n",
    "    img,h=load(out_path+\"res.nii.gz\")\n",
    "    if(ismask==1):\n",
    "        img[img>0]=1\n",
    "    rezized_image=np.zeros(size,dtype=np.uint16)\n",
    "    print(img.shape,rezized_image.shape,volume.GetOrigin(),original_spacing)\n",
    "    img_shapes=img.shape\n",
    "    center=np.divide(rezized_image.shape,2)\n",
    "    start_pos=np.divide(img_shapes,2)\n",
    "    start_pos=center-start_pos\n",
    "    rezized_image[int(start_pos[0]):int(start_pos[0])+img_shapes[0],int(start_pos[1]):int(start_pos[1])+img_shapes[1],int(start_pos[2]):int(start_pos[2])+img_shapes[2]]=img\n",
    "    if (not os.path.exists(out_path+\"inex_train/\"+basename)):\n",
    "        os.makedirs(out_path+\"inex_train/\"+basename)\n",
    "    \n",
    "    filename=os.path.basename(volume_path)\n",
    "    save(rezized_image,out_path+\"inex_train/\"+basename+\"/\"+filename,hdr=h,use_compression=False)\n",
    "\n",
    "\n",
    "volume_path=\"/research/sharedresources/cbi/data_exchange/zakhagrp/presentations/DeepBrainIPP_dataset/tmp_inexvivo/\"\n",
    "out_path=\"/research/sharedresources/cbi/data_exchange/zakhagrp/presentations/DeepBrainIPP_dataset/resampled/\"\n",
    "new_spacing = [0.06, 0.06, 0.48]\n",
    "size=(448,448,48)\n",
    "#size=(256,224,288)\n",
    "#size=(448,448,384)\n",
    "#size=(320,320,48)\n",
    "\n",
    "for files in glob.glob(volume_path+\"*\"):\n",
    "    #imag_path=files\n",
    "    basename=os.path.basename(files)\n",
    "    print(basename)\n",
    "    imag_path=files+\"/\"+basename+\"_brain.nii.gz\"\n",
    "    seg_path=files+\"/\"+basename+\"_seg.nii.gz\"\n",
    "    original_image,h = load(imag_path) \n",
    "    mask,m= load(seg_path) \n",
    "    save(original_image,imag_path,hdr=h, use_compression=False)\n",
    "    save(mask,seg_path,hdr=h, use_compression=False)\n",
    "    resample_volume(imag_path,0,new_spacing,size,out_path,basename)\n",
    "    resample_volume(seg_path,1,new_spacing,size,out_path,basename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2:The apply Data augmentation to increase variability and number of training sample\n",
    "\n",
    "#### Change the value of following parameters:\n",
    "path= Location where you stored resampled volume (output of previous step)\n",
    "\n",
    "aug_path= location where you want to store augmented sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "from medpy.io import load,save\n",
    "import numpy, imageio\n",
    "import glob, os\n",
    "import shutil\n",
    "import itertools\n",
    "import random\n",
    "import scipy.ndimage as ndimage\n",
    "from skimage.measure import label,regionprops\n",
    "import random\n",
    "\n",
    "\n",
    "path=\"/research/sharedresources/cbi/data_exchange/zakhagrp/presentations/DeepBrainIPP_dataset/resampled/inex_train/\"\n",
    "aug_path=\"/research/sharedresources/cbi/data_exchange/zakhagrp/presentations/DeepBrainIPP_dataset/augmented_volume/\"\n",
    "if not os.path.exists(aug_path):\n",
    "    os.makedirs(aug_path)\n",
    "else:\n",
    "    shutil.rmtree(aug_path)\n",
    "    os.makedirs(aug_path)\n",
    "\n",
    "#define the augmentation amtrix\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Multiply((0.9,1.3 ), per_channel=0.2),\n",
    "    iaa.AllChannelsCLAHE(),\n",
    "    iaa.Fliplr(1), # horizontally flip 50% of all images\n",
    "    iaa.Flipud(1), # vertically flip 20% of all images\n",
    "    iaa.Dropout([0.01, 0.05]),      # drop 5% or 20% of all pixels\n",
    "    #iaa.Sharpen(alpha=(0, 1.0), lightness=(0.4, 3.5)),       # sharpen the image\n",
    "    #affine transformation\n",
    "    #iaa.PiecewiseAffine(scale=(0.01, 0.05)),\n",
    "    \n",
    "    #PiecewiseAffine and elastic deformation\n",
    "    iaa.PiecewiseAffine(scale=(0.01, 0.05)),\n",
    "    iaa.ElasticTransformation(alpha=30, sigma=9),\n",
    "    iaa.ElasticTransformation(alpha=40, sigma=10),  # apply water effect (affects segmaps)\n",
    "    iaa.ElasticTransformation(alpha=50, sigma=11),  # apply water effect (affects segmaps)\n",
    "    iaa.ElasticTransformation(alpha=(2.5,3.0), sigma=1),\n",
    "    iaa.ElasticTransformation(alpha=(4.0,5.0), sigma=2.0),  # apply water effect (affects segmaps)\n",
    "    iaa.ElasticTransformation(alpha=(8.0,11.0), sigma=3.0),  # apply water effect (affects segmaps)\n",
    "    iaa.ElasticTransformation(alpha=(13.0,15.0), sigma=5),  # apply water effect (affects segmaps)\n",
    "    iaa.ElasticTransformation(alpha=(20.0,25.0), sigma=8),  # apply water effect (affects segmaps)\n",
    "    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
    "    iaa.PiecewiseAffine(scale=(0.02, 0.07)) ,\n",
    "    iaa.GaussianBlur(sigma=(1.5)),\n",
    "    iaa.GaussianBlur(sigma=(1.0)),\n",
    "    iaa.GaussianBlur(sigma=(0.8)),\n",
    "   \n",
    "    iaa.Affine(rotate=(-20, -15),\n",
    "            translate_percent={\"x\": (-0.05, 0.05), \"y\": (-0.05, 0.05),\"z\": (-0.05, 0.05)},\n",
    "            scale={\"x\": (0.8), \"y\": (0.8),\"z\":(0.8)}, order=3,\n",
    "            ),\n",
    "    \n",
    "    iaa.Affine(rotate=(-15, -10),\n",
    "            translate_percent={\"x\": (-0.05, 0.05), \"y\": (-0.05, 0.05),\"z\": (-0.05, 0.05)},\n",
    "            scale={\"x\": (0.9), \"y\": (0.9),\"z\":(0.9)}, order=3,\n",
    "            ),\n",
    "    iaa.Affine(rotate=(-10, -5),\n",
    "            translate_percent={\"x\": (-0.05, 0.05), \"y\": (-0.05, 0.05),\"z\": (-0.05, 0.05)},\n",
    "            scale={\"x\": (1.2), \"y\": (1.2),\"z\":(1.2)}, order=3,\n",
    "            ),\n",
    "    \n",
    "    iaa.Affine(rotate=(5, 10),\n",
    "            translate_percent={\"x\": (-0.05, 0.05), \"y\": (-0.05, 0.05),\"z\": (-0.05, 0.05)},\n",
    "            scale={\"x\": (1.3), \"y\": (1.3),\"z\":(1.3)}, order=3,\n",
    "            ),\n",
    "    iaa.Affine(rotate=(10, 15),\n",
    "            translate_percent={\"x\": (-0.05, 0.05), \"y\": (-0.05, 0.05),\"z\": (-0.05, 0.05)},\n",
    "            scale={\"x\": (0.9), \"y\": (0.9),\"z\":(0.9)}, order=3,\n",
    "            ),\n",
    "     iaa.Affine(rotate=(15, 20),\n",
    "            translate_percent={\"x\": (-0.05, 0.05), \"y\": (-0.05, 0.05),\"z\": (-0.05, 0.05)},\n",
    "            scale={\"x\": (0.8), \"y\": (0.8),\"z\":(0.8)}, order=3,\n",
    "            ),\n",
    "    \n",
    "              \n",
    "], random_order=False)\n",
    "\n",
    "#change data orientations\n",
    "def permute_data(data, key):\n",
    "    \"\"\"\n",
    "    Permutes the given data according to the specification of the given key. Input data\n",
    "    must be of shape (n_modalities, x, y, z).\n",
    "\n",
    "    Input key is a tuple: (rotate_y, rotate_z), flip_x, flip_y, flip_z, transpose)\n",
    "\n",
    "    As an example, ((0, 1), 0, 1, 0, 1) represents a permutation in which the data is\n",
    "    rotated 90 degrees around the z-axis, then reversed on the y-axis, and then\n",
    "    transposed.\n",
    "    \"\"\"\n",
    "    data = np.copy(data)\n",
    "    (rotate_y, rotate_z), flip_x, flip_y, flip_z, transpose = key\n",
    "\n",
    "    if rotate_y != 0:\n",
    "        data = np.rot90(data, rotate_y, axes=(0, 2))\n",
    "    if rotate_z != 0:\n",
    "        data = np.rot90(data, rotate_z, axes=(1, 2))\n",
    "    if flip_x:\n",
    "        data = data[:, ::-1]\n",
    "    if flip_y:\n",
    "        data = data[:, :, ::-1]\n",
    "    if flip_z:\n",
    "        data = data[:, :, ::-1]\n",
    "    return data\n",
    "def crop_volume_2(img,mask,thresholds):\n",
    "    tmp_mask=np.zeros_like(mask)\n",
    "    tmp_mask[mask==1.0]=1\n",
    "    center_mass=ndimage.measurements.center_of_mass(mask)   \n",
    "    x=int(center_mass[0]-thresholds[0])\n",
    "    y=int(center_mass[1]-thresholds[1])+thresholds[3]\n",
    "    z=int(center_mass[2]-thresholds[2])\n",
    "    if x<0:\n",
    "        x=0\n",
    "    if y<0:\n",
    "        y=0\n",
    "    if z<0:\n",
    "        z=0\n",
    "    \n",
    "    mask=mask[x:x+2*thresholds[0],y:y+2*thresholds[1],z:z+2*thresholds[2]]\n",
    "    img=img[x:x+2*thresholds[0],y:y+2*thresholds[1],z:z+2*thresholds[2]]\n",
    "    return img,mask\n",
    "\n",
    "def crop_volume(img,mask,thresholds):\n",
    "    tmp_mask=np.zeros((thresholds[0],thresholds[1],thresholds[2]),dtype=mask.dtype)\n",
    "    tmp_img=np.zeros((thresholds[0],thresholds[1],thresholds[2]),dtype=img.dtype)\n",
    "    \n",
    "    center_mass=ndimage.measurements.center_of_mass(img)   \n",
    "    x=int(center_mass[0]-thresholds[0])\n",
    "    y=int(center_mass[1]-thresholds[1])+thresholds[3]\n",
    "    z=int(center_mass[2]-thresholds[2])\n",
    "    if x<0:\n",
    "        x=0\n",
    "    if y<0:\n",
    "        y=0\n",
    "    if z<0:\n",
    "        z=0\n",
    "    \n",
    "    tmp_mask[:img.shape[0],:img.shape[1],:img.shape[2]]=mask\n",
    "    tmp_img[:img.shape[0],:img.shape[1],:img.shape[2]]=img\n",
    "    return tmp_img,tmp_mask\n",
    "def rotate_volume(img,seg_img, axes,prefix,img_header,seg_header,thresholds):\n",
    "        \n",
    "        deg=[-20,-15,-10,-5,5,10,15,20]\n",
    "        i=0\n",
    "        for angl in deg:\n",
    "\n",
    "            rotated_img=ndimage.interpolation.rotate(img,angle=angl,axes=axes,order=5, reshape=False, mode=\"constant\");\n",
    "            #rotated_seg=seg_img\n",
    "            #rotated_seg=ndimage.filters.median_filter(seg_img, mode=\"constant\", size=(5,5,3))\n",
    "            #rotated_seg[rotated_seg>0]=2**15\n",
    "            rotated_seg=ndimage.interpolation.rotate(rotated_seg,angle=angl,axes=axes,reshape=False,order=1,mode=\"constant\");\n",
    "            rotated_seg[rotated_seg>0.0]=1.0\n",
    "            rotated_seg[rotated_seg<=0.0]=0.0\n",
    "            #rotated_seg=ndimage.filters.median_filter(rotated_seg, mode=\"constant\", size=(5,5,3))\n",
    "            os.makedirs(aug_path+dirname+prefix+\"_\"+str(i))\n",
    "            rotated_img,rotated_seg=crop_volume(rotated_img,rotated_seg,thresholds)\n",
    "            save(rotated_img,aug_path+dirname+prefix+\"_\"+str(i)+\"/\"+dirname+prefix+\"_\"+str(i)+\"_brain.nii.gz\",hdr=img_header,use_compression=False)\n",
    "            save(rotated_seg,aug_path+dirname+prefix+\"_\"+str(i)+\"/\"+dirname+prefix+\"_\"+str(i)+\"_seg.nii.gz\",hdr=seg_header,use_compression=False)\n",
    "            i=i+1\n",
    "\n",
    "def zoom_image(img,seg_img,prefix,img_header,seg_header):\n",
    "    factors=[0.8,0.9,1.1,1.2]\n",
    "    i=0\n",
    "    for factor in factors:\n",
    "        rotated_img=ndimage.zoom(img,zoom=factor,mode='nearest', order=5);\n",
    "        rotated_seg=ndimage.zoom(seg_img,zoom=factor,mode='nearest', order=0);\n",
    "        os.makedirs(aug_path+dirname+prefix+\"_\"+str(i))\n",
    "        save(rotated_img,aug_path+dirname+prefix+\"_\"+str(i)+\"/\"+dirname+prefix+\"_\"+str(i)+\"_brain.nii.gz\",hdr=img_header,use_compression=False)\n",
    "        save(rotated_seg,aug_path+dirname+prefix+\"_\"+str(i)+\"/\"+dirname+prefix+\"_\"+str(i)+\"_seg.nii.gz\",hdr=seg_header,use_compression=False)\n",
    "        i=i+1\n",
    "    \n",
    "\n",
    "      \n",
    "def apply_augmentation(seq_picked,image,segmap,dirname,i,img_header,seg_header, thresholds):\n",
    "    \"\"\" apply augmentation on each image and mask\n",
    "    \"\"\"\n",
    "    dist_image, dist_mask= seq_picked(image=image, segmentation_maps=segmap)\n",
    "    os.makedirs(aug_path+dirname+\"_\"+str(i))\n",
    "    #print(dist_mask.shape)\n",
    "    dist_image,dist_mask=crop_volume(dist_image,dist_mask.get_arr(), thresholds)\n",
    "    save(dist_mask,aug_path+dirname+\"_\"+str(i)+\"/\"+dirname+\"_\"+str(i)+\"_seg.nii.gz\",hdr=seg_header,use_compression=False)\n",
    "    save(dist_image,aug_path+dirname+\"_\"+str(i)+\"/\"+dirname+\"_\"+str(i)+\"_brain.nii.gz\",hdr=img_header,use_compression=False)\n",
    "    \n",
    "    return dist_image\n",
    "\n",
    "thresholds=(448,448,48,0)\n",
    "#thresholds=(128,112,144,0)\n",
    "#thresholds=(128,112,144,0)\n",
    "\n",
    "#read all files and apply augmentation\n",
    "for file in glob.glob(path+\"*\"):\n",
    "    \"\"\" apply augmentation on each image and mask\"\"\"\n",
    "    dirname=os.path.basename(file)\n",
    "    print(dirname)\n",
    "    image_path=file+\"/\"+dirname+\"_brain.nii.gz\"\n",
    "    mask_path=file+\"/\"+dirname+\"_seg.nii.gz\"\n",
    "    image,img_header=load(image_path)\n",
    "    mask,seg_header=load(mask_path)\n",
    "    \n",
    "    #mask=ndimage.filters.median_filter(mask, mode=\"constant\", size=(3,3,3))\n",
    "    \n",
    "    segmap = SegmentationMapsOnImage(mask, shape=image.shape)\n",
    "    seq_all=[]\n",
    "    \n",
    "    \n",
    "    for i in range(len(seq)):\n",
    "        \n",
    "        seq_picked=iaa.Sequential([seq[i]])\n",
    "        apply_augmentation(seq_picked,image,segmap,dirname,i,img_header,seg_header,thresholds)\n",
    "        seq_all.append(seq[i])\n",
    "\n",
    "    \n",
    "        \n",
    "    '''\n",
    "    image_scale=ndimage.zoom(image,(1.3,1.3,5),order=3)\n",
    "    mask_scale=ndimage.zoom(mask,(1.3,1.3,5),order=3)\n",
    "    segmap = SegmentationMapsOnImage(mask_scale, shape=image_scale.shape)\n",
    "    sel_indx=[2,3, 4,5,6,7,8,9]\n",
    "    for i in sel_indx:\n",
    "        seq_picked=iaa.Sequential([seq[1],seq[i]])\n",
    "        ret_img=apply_augmentation(seq_picked,image_scale,segmap,dirname,i+100)\n",
    "    '''\n",
    "    \n",
    "   \n",
    "    #seq_picked=iaa.Sequential(seq_all)\n",
    "    #apply_augmentation(seq_picked,image,segmap,dirname,len(dict_aug)-1)\n",
    "    #image=exposure.equalize_adapthist(image)\n",
    "    \n",
    "    #zoom_image(image,mask,\"zoom\",img_header,seg_header)\n",
    "    #rotate_volume(image,mask, (0,2),\"roty\",img_header,seg_header,thresholds)\n",
    "    #rotate_volume(image,mask, (1,2),\"rotx\",img_header,seg_header,thresholds)\n",
    "    \n",
    "    os.makedirs(aug_path+dirname)\n",
    "    image,mask=crop_volume(image,mask,thresholds)\n",
    "    save(image,aug_path+dirname+\"/\"+dirname+\"_brain.nii.gz\",hdr=img_header, use_compression=False)\n",
    "    save(mask,aug_path+dirname+\"/\"+dirname+\"_seg.nii.gz\",hdr=seg_header, use_compression=False)\n",
    "    \n",
    "    '''\n",
    "    keys=set(itertools.product(itertools.combinations_with_replacement(range(2), 2), range(2), range(2), range(2), range(2)))\n",
    "    key=random.choice(list(keys))\n",
    "    dist_image = permute_data(image,key)\n",
    "    dist_mask = permute_data(mask,key)\n",
    "    \n",
    "    os.makedirs(aug_path+dirname+\"rotx\")\n",
    "    save(dist_image,aug_path+dirname+\"rotx/\"+dirname+\"rotx_brain.nii.gz\")\n",
    "    save(dist_mask,aug_path+dirname+\"rotx/\"+dirname+\"rotx_seg.nii.gz\")\n",
    "    '''   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Check all volumes have same dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check incorrect shape or corrupted data\n",
    "import glob, sys, os\n",
    "import numpy as np\n",
    "from medpy.io import load,save\n",
    "path=\"/research/sharedresources/cbi/data_exchange/zakhagrp/presentations/DeepBrainIPP_dataset/augmented_volume/\"\n",
    "for files in glob.glob(path+\"*\"):\n",
    "    basename=os.path.basename(files)\n",
    "    img,h=load(files+\"/\"+basename+\"_brain.nii.gz\")\n",
    "    seg,h=load(files+\"/\"+basename+\"_seg.nii.gz\")\n",
    "    #print(seg.shape)\n",
    "    shape=(448,448,48)\n",
    "    if (len(seg.shape)>2):\n",
    "        \n",
    "        if(img.shape[0]!=shape[0] or img.shape[1]!=shape[1] or img.shape[2]!=shape[2] or img.shape[0]!=seg.shape[0] or img.shape[1]!=seg.shape[1]  or img.shape[2]!=seg.shape[2] or np.max(seg)!=1 or np.min(seg)!=0 or img.shape[2]!=seg.shape[2] or np.max(img)==0 ):\n",
    "            print(\"corrupted\",basename)\n",
    "    else:\n",
    "        print(basename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step : Training model\n",
    "\n",
    "#### Parameters: There are several parameters need to find or set. Follow the draft manuscript for various parameter to build models\n",
    "file_path= Path where you stored augmented sample. Outcome of previous step\n",
    "\n",
    "data_path=Path where you want to store models\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys\n",
    "import glob\n",
    "sys.path.append('/lustre_scratch/sandbox/salam/cnn/3DUnetCNN/')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "from unet3d.data import write_data_to_file, open_data_file\n",
    "from unet3d.generator import get_training_and_validation_generators\n",
    "from unet3d.model import isensee2017_model\n",
    "from unet3d.training import load_old_model, train_model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import keras\n",
    "\n",
    "file_path=\"/research/sharedresources/cbi/data_exchange/zakhagrp/presentations/DeepBrainIPP_dataset/augmented_volume/\"\n",
    "data_path=\"/research/sharedresources/cbi/data_exchange/zakhagrp/presentations/DeepBrainIPP_dataset/model/\"\n",
    "output_model_path=data_path\n",
    "config = dict()\n",
    "config[\"gpu\"]=4\n",
    "config[\"image_shape\"] = (448, 448, 48)  # This determines what shape the images will be cropped/resampled to.\n",
    "config[\"patch_shape\"] =None#(128,128,128)#None  # switch to None to train on the whole image\n",
    "config[\"labels\"] = (1)  # the label numbers on the input image\n",
    "config[\"n_base_filters\"] = 16  # these are doubled after each downsampling\n",
    "config[\"n_labels\"] =1# len(config[\"labels\"])\n",
    "config[\"all_modalities\"] = [\"brain\"]  # set for the brats data\n",
    "config[\"training_modalities\"] = config[\"all_modalities\"]  # change this if you want to only use some of the modalities\n",
    "config[\"nb_channels\"] = len(config[\"training_modalities\"])\n",
    "if \"patch_shape\" in config and config[\"patch_shape\"] is not None:\n",
    "    config[\"input_shape\"] = tuple([config[\"nb_channels\"]] + list(config[\"patch_shape\"]))\n",
    "else:\n",
    "    config[\"input_shape\"] = tuple([config[\"nb_channels\"]] + list(config[\"image_shape\"]))\n",
    "config[\"truth_channel\"] = config[\"nb_channels\"]\n",
    "config[\"deconvolution\"] = False  # if False, will use upsampling instead of deconvolution\n",
    "\n",
    "config[\"batch_size\"] =1\n",
    "config[\"validation_batch_size\"] =1\n",
    "config[\"n_epochs\"] = 500  # cutoff the training after this many epochs\n",
    "config[\"patience\"] = 15  # learning rate will be reduced after this many epochs if the validation loss is not improving\n",
    "config[\"early_stop\"] = 100  # training will be stopped after this many epochs without the validation loss improving\n",
    "config[\"initial_learning_rate\"] = 5e-5\n",
    "config[\"learning_rate_drop\"] = 0.7  # factor by which the learning rate will be reduced\n",
    "config[\"validation_split\"] = 0.8  # portion of the data that will be used for training\n",
    "config[\"flip\"] = False  # augments the data by randomly flipping an axis during\n",
    "config[\"permute\"] = False  # data shape must be a cube. Augments the data by permuting in various directions\n",
    "config[\"distort\"] = False  # switch to None if you want no distortion\n",
    "config[\"augment\"] = config[\"flip\"] or config[\"distort\"]\n",
    "config[\"patch_overlap\"] = 0  # if > 0, during training, validation patches will be overlapping\n",
    "config[\"training_patch_start_offset\"] = (16, 16, 16)  # randomly offset the first patch index by up to this offset\n",
    "config[\"skip_blank\"] = True  # if True, then patches without any target will be skipped\n",
    "\n",
    "config[\"data_file\"] = os.path.abspath(data_path+\"brain_data.h5\")\n",
    "config[\"model_file\"] = os.path.abspath(output_model_path+\"brain_unet_model-{epoch:02d}.h5\")\n",
    "config[\"training_file\"] = os.path.abspath(data_path+\"brain_training_ids.pkl\")\n",
    "config[\"validation_file\"] = os.path.abspath(data_path+\"brain_validation_ids.pkl\")\n",
    "config[\"overwrite\"] = False  # If True, will previous files. If False, will use previously written files.\n",
    "\n",
    "\n",
    "def fetch_mouse_2020_files(modalities, group=\"Training\", include_truth=True, return_subject_ids=False):\n",
    "    training_data_files = list()\n",
    "    subject_ids = list()\n",
    "    modalities = list(modalities)\n",
    "    if include_truth:\n",
    "        modalities = modalities + [\"seg\"]\n",
    "    #print(os.path.join(os.path.dirname(files_dir), \"data\", \"*{0}*\", \"*{0}*\").format(group))\n",
    "    for subject_dir in glob.glob(file_path+\"/*\"):\n",
    "        subject_id = os.path.basename(subject_dir)\n",
    "        \n",
    "        subject_ids.append(subject_id)\n",
    "        subject_files = list()\n",
    "        for modality in modalities:\n",
    "            subject_files.append(os.path.join(subject_dir, subject_id + \"_\" + modality + \".nii.gz\"))\n",
    "            #print(os.path.join(subject_dir, subject_id + \"_\" + modality + \".nii.gz\"))\n",
    "        training_data_files.append(tuple(subject_files))\n",
    "    if return_subject_ids:\n",
    "        return training_data_files, subject_ids\n",
    "    else:\n",
    "        return training_data_files\n",
    "\n",
    "\n",
    "def fetch_training_data_files(return_subject_ids=False):\n",
    "    return fetch_mouse_2020_files(modalities=config[\"training_modalities\"],include_truth=True, return_subject_ids=return_subject_ids)\n",
    "\n",
    "\n",
    "def main(overwrite=False):\n",
    "    # convert input images into an hdf5 file\n",
    "    if overwrite or not os.path.exists(config[\"data_file\"]):\n",
    "        training_files, subject_ids = fetch_training_data_files(return_subject_ids=True)\n",
    "\n",
    "        write_data_to_file(training_files, config[\"data_file\"], image_shape=config[\"image_shape\"],\n",
    "                           subject_ids=subject_ids)\n",
    "    data_file_opened = open_data_file(config[\"data_file\"])\n",
    "\n",
    "    #if not overwrite and os.path.exists(config[\"model_file\"]):\n",
    "        #model = load_old_model(config[\"model_file\"])\n",
    "    #else:\n",
    "        # instantiate new model\n",
    "    model = isensee2017_model(input_shape=config[\"input_shape\"], n_labels=config[\"n_labels\"],\n",
    "                              initial_learning_rate=config[\"initial_learning_rate\"],\n",
    "                              n_base_filters=config[\"n_base_filters\"],depth=5,dropout_rate=0.1,gpu=config[\"gpu\"])\n",
    "    #print(model.summary())\n",
    "    #tf.keras.utils.plot_model(\n",
    "    #model, to_file='model.png', show_shapes=False, show_layer_names=True,\n",
    "    #rankdir='LR', expand_nested=False, dpi=96)\n",
    "\n",
    "    # get training and testing generators\n",
    "    train_generator, validation_generator, n_train_steps, n_validation_steps = get_training_and_validation_generators(\n",
    "        data_file_opened,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        data_split=config[\"validation_split\"],\n",
    "        overwrite=overwrite,\n",
    "        validation_keys_file=config[\"validation_file\"],\n",
    "        training_keys_file=config[\"training_file\"],\n",
    "        n_labels=config[\"n_labels\"],\n",
    "        labels=config[\"labels\"],\n",
    "        patch_shape=config[\"patch_shape\"],\n",
    "        validation_batch_size=config[\"validation_batch_size\"],\n",
    "        validation_patch_overlap=config[\"patch_overlap\"],\n",
    "        training_patch_start_offset=config[\"training_patch_start_offset\"],\n",
    "        permute=config[\"permute\"],\n",
    "        augment=config[\"augment\"],\n",
    "        skip_blank=config[\"skip_blank\"],\n",
    "        augment_flip=config[\"flip\"],\n",
    "        augment_distortion_factor=config[\"distort\"],\n",
    "        patch_overlap=config[\"patch_overlap\"])\n",
    "\n",
    "    # run training\n",
    "    history=train_model(model=model,\n",
    "                model_file=config[\"model_file\"],\n",
    "                training_generator=train_generator,\n",
    "                validation_generator=validation_generator,\n",
    "                steps_per_epoch=n_train_steps,\n",
    "                validation_steps=n_validation_steps,\n",
    "                initial_learning_rate=config[\"initial_learning_rate\"],\n",
    "                learning_rate_drop=config[\"learning_rate_drop\"],\n",
    "                learning_rate_patience=config[\"patience\"],\n",
    "                early_stopping_patience=config[\"early_stop\"],\n",
    "                n_epochs=config[\"n_epochs\"])\n",
    "    data_file_opened.close()\n",
    "    return history\n",
    "\n",
    "\n",
    "history=main(overwrite=config[\"overwrite\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
