{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/ellisdg/3DUnetCNN\n",
    "#https://www.biorxiv.org/content/10.1101/2020.02.25.964015v1.full\n",
    "import os, sys\n",
    "import glob\n",
    "sys.path.append('/lustre_scratch/sandbox/salam/cnn/3DUnetCNN/')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3,7,2,1\"\n",
    "from unet3d.data import write_data_to_file, open_data_file\n",
    "from unet3d.generator_sequence import get_validation_split\n",
    "from unet3d.generator_sequence import DataGenerator\n",
    "from unet3d.model import isensee2017\n",
    "from unet3d.training import load_old_model, train_model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import tensorflow as tf\n",
    "import threading\n",
    "import faulthandler\n",
    "import unet3d.generator\n",
    "faulthandler.enable()\n",
    "\n",
    "file_path=\"/lustre_scratch/sandbox/salam/cnn/3DUnetCNN/brats/data/training/inex_train_uniform/inex_train_iso_v1/inex_whole_brain/\"\n",
    "data_path=\"/lustre_scratch/sandbox/salam/models_tmp/\"\n",
    "output_model_path=data_path\n",
    "#BraTS_2020_subject_ID\n",
    "config = dict()\n",
    "config[\"gpu\"]=4\n",
    "config[\"image_shape\"] = (320, 256, 320)  # This determines what shape the images will be cropped/resampled to.\n",
    "config[\"patch_shape\"] =(320,256,80)#None  # switch to None to train on the whole image\n",
    "config[\"labels\"] = (1)  # the label numbers on the input image\n",
    "config[\"n_base_filters\"] = 16  # these are doubled after each downsampling\n",
    "config[\"n_labels\"] =1# len(config[\"labels\"])\n",
    "config[\"all_modalities\"] = [\"brain\"]  # set for the brats data\n",
    "config[\"training_modalities\"] = config[\"all_modalities\"]  # change this if you want to only use some of the modalities\n",
    "config[\"nb_channels\"] = len(config[\"training_modalities\"])\n",
    "if \"patch_shape\" in config and config[\"patch_shape\"] is not None:\n",
    "    config[\"input_shape\"] = tuple([config[\"nb_channels\"]] + list(config[\"patch_shape\"]))\n",
    "else:\n",
    "    config[\"input_shape\"] = tuple([config[\"nb_channels\"]] + list(config[\"image_shape\"]))\n",
    "config[\"truth_channel\"] = config[\"nb_channels\"]\n",
    "config[\"deconvolution\"] = False  # if False, will use upsampling instead of deconvolution\n",
    "\n",
    "config[\"batch_size\"] =4\n",
    "config[\"validation_batch_size\"] =4\n",
    "config[\"n_epochs\"] = 16  # cutoff the training after this many epochs\n",
    "config[\"patience\"] = 10  # learning rate will be reduced after this many epochs if the validation loss is not improving\n",
    "config[\"early_stop\"] = 100  # training will be stopped after this many epochs without the validation loss improving\n",
    "config[\"initial_learning_rate\"] = 5e-5\n",
    "config[\"learning_rate_drop\"] = 0.7  # factor by which the learning rate will be reduced\n",
    "config[\"validation_split\"] = 0.8  # portion of the data that will be used for training\n",
    "config[\"flip\"] = False  # augments the data by randomly flipping an axis during\n",
    "config[\"permute\"] = False  # data shape must be a cube. Augments the data by permuting in various directions\n",
    "config[\"distort\"] = False  # switch to None if you want no distortion\n",
    "config[\"augment\"] = config[\"flip\"] or config[\"distort\"]\n",
    "config[\"patch_overlap\"] = 0  # if > 0, during training, validation patches will be overlapping\n",
    "config[\"training_patch_start_offset\"] = (0, 0, 0)  # randomly offset the first patch index by up to this offset\n",
    "config[\"skip_blank\"] = True  # if True, then patches without any target will be skipped\n",
    "\n",
    "config[\"data_file\"] = os.path.abspath(data_path+\"brain_data.h5\")\n",
    "config[\"model_file\"] = os.path.abspath(output_model_path+\"brain_unet_model-{epoch:02d}.h5\")\n",
    "config[\"training_file\"] = os.path.abspath(data_path+\"brain_training_ids.pkl\")\n",
    "config[\"validation_file\"] = os.path.abspath(data_path+\"brain_validation_ids.pkl\")\n",
    "config[\"overwrite\"] = False  # If True, will previous files. If False, will use previously written files.\n",
    "\n",
    "#write_data_to_file-->Utils.read_image_files\n",
    "\n",
    "def fetch_brats_2020_files(modalities, group=\"Training\", include_truth=True, return_subject_ids=False):\n",
    "    training_data_files = list()\n",
    "    subject_ids = list()\n",
    "    modalities = list(modalities)\n",
    "    if include_truth:\n",
    "        modalities = modalities + [\"seg\"]\n",
    "    #print(os.path.join(os.path.dirname(files_dir), \"data\", \"*{0}*\", \"*{0}*\").format(group))\n",
    "    for subject_dir in glob.glob(file_path+\"/*\"):\n",
    "        subject_id = os.path.basename(subject_dir)\n",
    "        \n",
    "        subject_ids.append(subject_id)\n",
    "        subject_files = list()\n",
    "        for modality in modalities:\n",
    "            subject_files.append(os.path.join(subject_dir, subject_id + \"_\" + modality + \".nii.gz\"))\n",
    "            #print(os.path.join(subject_dir, subject_id + \"_\" + modality + \".nii.gz\"))\n",
    "        training_data_files.append(tuple(subject_files))\n",
    "    if return_subject_ids:\n",
    "        return training_data_files, subject_ids\n",
    "    else:\n",
    "        return training_data_files\n",
    "\n",
    "\n",
    "def fetch_training_data_files(return_subject_ids=False):\n",
    "    return fetch_brats_2020_files(modalities=config[\"training_modalities\"],include_truth=True, return_subject_ids=return_subject_ids)\n",
    "\n",
    "\n",
    "def main(overwrite=False):\n",
    "    # convert input images into an hdf5 file\n",
    "    if overwrite or not os.path.exists(config[\"data_file\"]):\n",
    "        training_files, subject_ids = fetch_training_data_files(return_subject_ids=True)\n",
    "\n",
    "        write_data_to_file(training_files, config[\"data_file\"], image_shape=config[\"image_shape\"],\n",
    "                           subject_ids=subject_ids)\n",
    "    data_file_opened = open_data_file(config[\"data_file\"])\n",
    "\n",
    "    #if not overwrite and os.path.exists(config[\"model_file\"]):\n",
    "        #model = load_old_model(config[\"model_file\"])\n",
    "    #else:\n",
    "        # instantiate new model\n",
    "    model = isensee2017.isensee2017_model(input_shape=config[\"input_shape\"], n_labels=config[\"n_labels\"],\n",
    "                              initial_learning_rate=config[\"initial_learning_rate\"],\n",
    "                              n_base_filters=config[\"n_base_filters\"],depth=5,dropout_rate=0.08,gpu=config[\"gpu\"])\n",
    "    #print(model.summary())\n",
    "    #tf.keras.utils.plot_model(\n",
    "    #model, to_file='model.png', show_shapes=False, show_layer_names=True,\n",
    "    #rankdir='LR', expand_nested=False, dpi=96)\n",
    "\n",
    "    # get training and testing generators\n",
    "    lock = threading.Lock()\n",
    "    \n",
    "    training_list, validation_list = get_validation_split(data_file_opened,\n",
    "                                                          data_split=onfig[\"validation_split\"]\n",
    "                                                          overwrite=overwrite,\n",
    "                                                          training_file=config[\"training_file\"],\n",
    "                                                          validation_file=config[\"validation_file\"],)\n",
    "    \n",
    "    train_generator=DataGenerator(data_file_opened,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        data_split=config[\"validation_split\"],\n",
    "        overwrite=overwrite,\n",
    "        validation_keys_file=config[\"validation_file\"],\n",
    "        training_keys_file=config[\"training_file\"],\n",
    "        n_labels=config[\"n_labels\"],\n",
    "        labels=config[\"labels\"],\n",
    "        patch_shape=config[\"patch_shape\"],\n",
    "        validation_batch_size=config[\"validation_batch_size\"],\n",
    "        validation_patch_overlap=config[\"patch_overlap\"],\n",
    "        training_patch_start_offset=config[\"training_patch_start_offset\"],\n",
    "        permute=config[\"permute\"],\n",
    "        augment=config[\"augment\"],\n",
    "        skip_blank=config[\"skip_blank\"],\n",
    "        augment_flip=config[\"flip\"],\n",
    "        augment_distortion_factor=config[\"distort\"],\n",
    "        patch_overlap=config[\"patch_overlap\"], ndex_list=training_list, locks)\n",
    "    validation_generator=DataGenerator(data_file_opened,\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        data_split=config[\"validation_split\"],\n",
    "        overwrite=overwrite,\n",
    "        validation_keys_file=config[\"validation_file\"],\n",
    "        training_keys_file=config[\"training_file\"],\n",
    "        n_labels=config[\"n_labels\"],\n",
    "        labels=config[\"labels\"],\n",
    "        patch_shape=config[\"patch_shape\"],\n",
    "        validation_batch_size=config[\"validation_batch_size\"],\n",
    "        validation_patch_overlap=config[\"patch_overlap\"],\n",
    "        training_patch_start_offset=config[\"training_patch_start_offset\"],\n",
    "        permute=config[\"permute\"],\n",
    "        augment=config[\"augment\"],\n",
    "        skip_blank=config[\"skip_blank\"],\n",
    "        augment_flip=config[\"flip\"],\n",
    "        augment_distortion_factor=config[\"distort\"],\n",
    "        patch_overlap=config[\"patch_overlap\"], ndex_list=validation_list, locks)\n",
    "    \n",
    "    n_train_steps=train_generator.num_training_steps\n",
    "     \n",
    "    n_validation_steps=validation_generator.num_validation_steps\n",
    "    # run training\n",
    "    \n",
    "    history=train_model(model=model,\n",
    "                model_file=config[\"model_file\"],\n",
    "                training_generator=train_generator,\n",
    "                validation_generator=validation_generator,\n",
    "                steps_per_epoch=n_train_steps,\n",
    "                validation_steps=n_validation_steps,\n",
    "                initial_learning_rate=config[\"initial_learning_rate\"],\n",
    "                learning_rate_drop=config[\"learning_rate_drop\"],\n",
    "                learning_rate_patience=config[\"patience\"],\n",
    "                early_stopping_patience=config[\"early_stop\"],\n",
    "                n_epochs=config[\"n_epochs\"])\n",
    "    data_file_opened.close()\n",
    "    return history\n",
    "\n",
    "\n",
    "history=main(overwrite=config[\"overwrite\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
