{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "from random import shuffle\n",
    "import itertools\n",
    "import traceback\n",
    "import threading\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from .utils import pickle_dump, pickle_load\n",
    "from .utils.patches import compute_patch_indices, get_random_nd_index, get_patch_from_3d_data\n",
    "from .augment import augment_data, random_permutation_x_y\n",
    "\n",
    "\n",
    "def get_validation_split(data_file, training_file, validation_file, data_split=0.8, overwrite=False):\n",
    "        \"\"\"\n",
    "        Splits the data into the training and validation indices list.\n",
    "        :param data_file: pytables hdf5 data file\n",
    "        :param training_file:\n",
    "        :param validation_file:\n",
    "        :param data_split:\n",
    "        :param overwrite:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if overwrite or not os.path.exists(training_file):\n",
    "            print(\"Creating validation split...\")\n",
    "            nb_samples = data_file.root.data.shape[0]\n",
    "            sample_list = list(range(nb_samples))\n",
    "            training_list, validation_list = split_list(sample_list, split=data_split)\n",
    "            pickle_dump(training_list, training_file)\n",
    "            pickle_dump(validation_list, validation_file)\n",
    "            return training_list, validation_list\n",
    "        else:\n",
    "            print(\"Loading previous validation split...\")\n",
    "            return pickle_load(training_file), pickle_load(validation_file)\n",
    "\n",
    "\n",
    "def split_list(input_list, split=0.8, shuffle_list=True):\n",
    "        if shuffle_list:\n",
    "            shuffle(input_list)\n",
    "        n_training = int(len(input_list) * split)\n",
    "        training = input_list[:n_training]\n",
    "        testing = input_list[n_training:]\n",
    "        return training, testing\n",
    "\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, data_file, batch_size, n_labels, training_keys_file, validation_keys_file,\n",
    "                                               data_split=0.8, overwrite=False, labels=None, augment=False,\n",
    "                                               augment_flip=True, augment_distortion_factor=0.25, patch_shape=None,\n",
    "                                               validation_patch_overlap=0, training_patch_start_offset=None,\n",
    "                                       validation_batch_size=None, skip_blank=True, permute=False, patch_overlap=0,isvalidation=False,index_list=None, locks):\n",
    "        \n",
    "        self.data_file=data_file\n",
    "        self.batch_size= batch_size\n",
    "        self.n_labels= n_labels\n",
    "        self.training_keys_file=training_keys_file\n",
    "        self.validation_keys_file=validation_keys_file\n",
    "        self.data_split=data_split \n",
    "        self.overwrite=overwrite\n",
    "        self.labels=labels\n",
    "        self.augment=augment\n",
    "        self.augment_flip=augment_flip\n",
    "        self.augment_distortion_factor=augment_distortion_factor\n",
    "        self.patch_shape=patch_shape                              \n",
    "        self.validation_patch_overlap=validation_patch_overlap\n",
    "        self.training_patch_start_offset=training_patch_start_offset\n",
    "        self.validation_batch_size=validation_batch_size\n",
    "        self.skip_blank=skip_blank \n",
    "        self.permute=permute\n",
    "        self.patch_overlap=patch_overlap\n",
    "        self.isvalidation=isvalidation\n",
    "        self.index_list=index_list\n",
    "        self.num_training_steps=0\n",
    "        self.num_validation_steps=0\n",
    "        \n",
    "        if not validation_batch_size:\n",
    "            self.validation_batch_size = batch_size\n",
    "            \n",
    "        if self.patch_shape:\n",
    "            self.index_list = self.create_patch_index_list(orig_index_list, data_file.root.data.shape[-3:], patch_shape,\n",
    "                                                 patch_overlap, patch_start_offset)\n",
    "        shuffle( self.index_list)\n",
    "        \n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        if (self.isvalidation==False):\n",
    "            num_training_steps =self.get_number_of_steps(get_number_of_patches(self.data_file, self.training_list, self.patch_shape,\n",
    "                                                                   skip_blank=self.skip_blank,\n",
    "                                                                   patch_start_offset=self.training_patch_start_offset,\n",
    "                                                                   patch_overlap=0), self.batch_size)                                                          patch_overlap=0), batch_size)\n",
    "            \n",
    "            print(\"Number of training steps: \", num_training_steps)\n",
    "            self.num_training_steps=num_training_steps\n",
    "            return num_training_steps\n",
    "        else:\n",
    "\n",
    "            num_validation_steps =self.get_number_of_steps(get_number_of_patches(self.data_file, self.validation_list, self.patch_shape,\n",
    "                                                                     skip_blank=self.skip_blank,\n",
    "                                                                     patch_overlap=self.validation_patch_overlap),validation_batch_size)\n",
    "            print(\"Number of validation steps: \", num_validation_steps)\n",
    "            self.num_validation_steps=num_validation_steps\n",
    "            return num_validation_steps\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        shuffle( self.index_list)\n",
    "        \n",
    "    def __getitem__(self):\n",
    "        'Generate one batch of data'\n",
    "        \n",
    "        x_list = list()\n",
    "        y_list = list()\n",
    "        while len(x_list)<self.batch_size:\n",
    "            index = self.index_list.pop()\n",
    "            self.add_data(x_list, y_list, self.data_file, index, augment=self.augment, augment_flip=self.augment_flip,\n",
    "                     augment_distortion_factor=self.augment_distortion_factor, patch_shape=self.patch_shape,\n",
    "                     skip_blank=self.skip_blank, permute=self.permute)\n",
    "            self.convert_data(x_list, y_list, n_labels=self.n_labels, labels=self.labels)\n",
    "          \n",
    "\n",
    "        return x_list, y_list\n",
    "    \n",
    "    \n",
    "    def get_number_of_patches(data_file, index_list, patch_shape=None, patch_overlap=0, patch_start_offset=None,\n",
    "                              skip_blank=True):\n",
    "        if patch_shape:\n",
    "            index_list = create_patch_index_list(index_list, data_file.root.data.shape[-3:], patch_shape, patch_overlap,\n",
    "                                                 patch_start_offset)\n",
    "            print(\"total indicess: \"+str(len(index_list)))\n",
    "            count = 0\n",
    "            for index in index_list:\n",
    "                x_list = list()\n",
    "                y_list = list()\n",
    "                add_data(x_list, y_list, data_file, index, skip_blank=skip_blank, patch_shape=patch_shape)\n",
    "                if len(x_list) > 0:\n",
    "                    count += 1\n",
    "                else:\n",
    "                    print(\"corr indx \",index)\n",
    "            return count\n",
    "        else:\n",
    "            return len(index_list)\n",
    "\n",
    "\n",
    "    def create_patch_index_list(index_list, image_shape, patch_shape, patch_overlap, patch_start_offset=None):\n",
    "        patch_index = list()\n",
    "        for index in index_list:\n",
    "            if patch_start_offset is not None:\n",
    "                random_start_offset = np.negative(get_random_nd_index(patch_start_offset))\n",
    "                patches = compute_patch_indices(image_shape, patch_shape, overlap=patch_overlap, start=random_start_offset)\n",
    "            else:\n",
    "                patches = compute_patch_indices(image_shape, patch_shape, overlap=patch_overlap)\n",
    "            patch_index.extend(itertools.product([index], patches))\n",
    "        return patch_index\n",
    "\n",
    "\n",
    "    def add_data(x_list, y_list, data_file, index, augment=False, augment_flip=False, augment_distortion_factor=0.25,\n",
    "                 patch_shape=False, skip_blank=True, permute=False):\n",
    "        \"\"\"\n",
    "        Adds data from the data file to the given lists of feature and target data\n",
    "        :param skip_blank: Data will not be added if the truth vector is all zeros (default is True).\n",
    "        :param patch_shape: Shape of the patch to add to the data lists. If None, the whole image will be added.\n",
    "        :param x_list: list of data to which data from the data_file will be appended.\n",
    "        :param y_list: list of data to which the target data from the data_file will be appended.\n",
    "        :param data_file: hdf5 data file.\n",
    "        :param index: index of the data file from which to extract the data.\n",
    "        :param augment: if True, data will be augmented according to the other augmentation parameters (augment_flip and\n",
    "        augment_distortion_factor)\n",
    "        :param augment_flip: if True and augment is True, then the data will be randomly flipped along the x, y and z axis\n",
    "        :param augment_distortion_factor: if augment is True, this determines the standard deviation from the original\n",
    "        that the data will be distorted (in a stretching or shrinking fashion). Set to None, False, or 0 to prevent the\n",
    "        augmentation from distorting the data in this way.\n",
    "        :param permute: will randomly permute the data (data must be 3D cube)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        data, truth = get_data_from_file(data_file, index, patch_shape=patch_shape)\n",
    "        if augment:\n",
    "            if patch_shape is not None:\n",
    "                affine = data_file.root.affine[index[0]]\n",
    "            else:\n",
    "                affine = data_file.root.affine[index]\n",
    "            data, truth = augment_data(data, truth, affine, flip=augment_flip, scale_deviation=augment_distortion_factor)\n",
    "\n",
    "        if permute:\n",
    "            if data.shape[-3] != data.shape[-2] or data.shape[-2] != data.shape[-1]:\n",
    "                raise ValueError(\"To utilize permutations, data array must be in 3D cube shape with all dimensions having \"\n",
    "                                 \"the same length.\")\n",
    "            data, truth = random_permutation_x_y(data, truth[np.newaxis])\n",
    "        else:\n",
    "            truth = truth[np.newaxis]\n",
    "\n",
    "        if not skip_blank or np.any(truth != 0):\n",
    "            x_list.append(data)\n",
    "            y_list.append(truth)\n",
    "        else:\n",
    "            print(\"cor shape \",data.shape,truth.shape, np.max(truth),index)\n",
    "\n",
    "\n",
    "    # +\n",
    "\n",
    "    def get_data_slice(data_file, index):\n",
    "        global locks\n",
    "        locks.acquire()\n",
    "        try:\n",
    "            if isinstance(index, int) and index>=0 and index<len(data_file.root.data) and index<len(data_file.root.truth): \n",
    "                x, y = data_file.root.data[index], data_file.root.truth[index, 0]\n",
    "            else:\n",
    "                print(\"Corrupted Index!!!!!!!!!!!!!!!!!!!!!!!! \",index)\n",
    "                index=0\n",
    "                x, y = data_file.root.data[index], data_file.root.truth[index, 0]\n",
    "        except Exception:\n",
    "            print(traceback.print_exc())\n",
    "            print(\"Corrupted Index!!!!!!!!!!!!!!!!!!!!!!!! \",index)\n",
    "            index=0\n",
    "            x, y = data_file.root.data[index], data_file.root.truth[index, 0]\n",
    "        locks.release()\n",
    "        return x,y\n",
    "\n",
    "    def get_data_from_file(data_file, index, patch_shape=None,lock=None):\n",
    "        if patch_shape is not None:\n",
    "            index, patch_index = index\n",
    "            data, truth = get_data_slice(data_file, index)\n",
    "            x = get_patch_from_3d_data(data, patch_shape, patch_index)\n",
    "            y = get_patch_from_3d_data(truth, patch_shape, patch_index)\n",
    "\n",
    "        else:\n",
    "            x,y=get_data_slice(data_file, index)\n",
    "        return x, y\n",
    "    # -\n",
    "\n",
    "\n",
    "\n",
    "    def convert_data(x_list, y_list, n_labels=1, labels=None):\n",
    "        x = np.asarray(x_list)\n",
    "        y = np.asarray(y_list)\n",
    "        if n_labels == 1:\n",
    "            y[y > 0] = 1\n",
    "        elif n_labels > 1:\n",
    "            y = get_multi_class_labels(y, n_labels=n_labels, labels=labels)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "    def get_multi_class_labels(data, n_labels, labels=None):\n",
    "        \"\"\"\n",
    "        Translates a label map into a set of binary labels.\n",
    "        :param data: numpy array containing the label map with shape: (n_samples, 1, ...).\n",
    "        :param n_labels: number of labels.\n",
    "        :param labels: integer values of the labels.\n",
    "        :return: binary numpy array of shape: (n_samples, n_labels, ...)\n",
    "        \"\"\"\n",
    "        new_shape = [data.shape[0], n_labels] + list(data.shape[2:])\n",
    "        y = np.zeros(new_shape, np.int8)\n",
    "        for label_index in range(n_labels):\n",
    "            if labels is not None:\n",
    "                y[:, label_index][data[:, 0] == labels[label_index]] = 1\n",
    "            else:\n",
    "                y[:, label_index][data[:, 0] == (label_index + 1)] = 1\n",
    "        return y\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
